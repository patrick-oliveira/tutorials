{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "         Date  Temperature\n",
      "0  01/01/2011         68.9\n",
      "1  01/02/2011         66.4\n",
      "2  01/03/2011         68.7\n",
      "3  01/04/2011         71.4\n",
      "4  01/05/2011         69.3\n",
      "Testing\n",
      "         Date  Temperature\n",
      "0  09/03/2019         73.4\n",
      "1  09/04/2019         71.6\n",
      "2  09/05/2019         71.7\n",
      "3  09/06/2019         71.6\n",
      "4  09/07/2019         71.3\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"/home/roboto/Documents/GitHub/tutorials/data/weather/training.csv\", sep = \"\\t\")\n",
    "testing_data  = pd.read_csv(\"/home/roboto/Documents/GitHub/tutorials/data/weather/testing.csv\", sep = \",\")\n",
    "# l1, l2 = len(training_data), len(testing_data)\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# training_data['Temperature'] = min_max_scaler.fit_transform(training_data['Temperature'].values.reshape(l1, -1))\n",
    "# testing_data['Temperature'] = min_max_scaler.fit_transform(testing_data['Temperature'].values.reshape(l2, -1))\n",
    "print(\"Training\")\n",
    "print(training_data.head())\n",
    "print(\"Testing\")\n",
    "print(testing_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherTemperatureDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        super(WeatherTemperatureDataset, self).__init__()\n",
    "        self.samples = []\n",
    "        self.generate_samples(dataframe)\n",
    "        \n",
    "    def generate_samples(self, dataframe):\n",
    "        series = dataframe['Temperature']\n",
    "        n_days = 1\n",
    "        for i in range(30, len(series) - n_days, 30):\n",
    "            _input = torch.tensor(series[i - 30: i].values, dtype = torch.float)\n",
    "            if True in torch.isnan(_input):\n",
    "                pass\n",
    "            else:\n",
    "                _input = _input.reshape(-1, 1)\n",
    "                target = torch.tensor(series[i:i+n_days].values, dtype = torch.float)\n",
    "                self.samples.append((_input, target))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = WeatherTemperatureDataset(training_data)\n",
    "testing_dataset  = WeatherTemperatureDataset(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "training_dataloader = DataLoader(training_dataset, shuffle = True, batch_size = batch_size, drop_last = True)\n",
    "testing_dataloader = DataLoader(testing_dataset, shuffle = True)\n",
    "sample = next(iter(training_dataloader))\n",
    "input_sample = sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Module__\n",
    "\n",
    "From this module, it's possible to build three basic types of architectures:\n",
    "\n",
    "- Recurrent networks that produce an output at each time step and have recurrent connections between hidden units\n",
    "- Recurrent networks that produce an output at each time step and have recurrent connections only from the output at one time step to the hidden units at the next time step\n",
    "- Recurrent networks with recurrent connections between hidden units, that read an entire sequence and then produce a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, hidden_activation = 'tanh', output_activation = 'sigmoid'):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size \n",
    "        \n",
    "        self.hidden_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.input_linear  = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.output_linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        self.hidden_activation = nn.functional.tanh\n",
    "        self.output_activation = nn.functional.sigmoid # Put a selection function here\n",
    "        \n",
    "        self.first = True # if True, the network wasn't used before\n",
    "        \n",
    "    def forward(self, X, Y: torch.Tensor = None):\n",
    "        '''\n",
    "        X(n_batches, sequence_length, num_features)\n",
    "        '''\n",
    "        if self.first:\n",
    "            self.initHidden()\n",
    "            self.first = False\n",
    "        \n",
    "        output = torch.cat(self.sequence_processing(X, Y), 1)\n",
    "        return output, self.hidden_state\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size, dtype = torch.float)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.first = True\n",
    "        \n",
    "    def sequence_processing(self, X: torch.Tensor, Y: torch.Tensor = None) -> List[torch.Tensor]:\n",
    "        raise NotImplementedError(\"Each subclass of a recurrent module class should implement it's own method to compute outputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_Saved_Hidden](Images/RNN_Saved_Hidden.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBasic(RNNModule):\n",
    "    # Returns one output for each sequence input, i.e. returns another whole sequence\n",
    "    # Each state is computed using the immidiate input and the previous hidden state.\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation = 'tanh', output_activation = 'sigmoid'):\n",
    "        super().__init__(input_size, hidden_size, output_size, activation)\n",
    "        \n",
    "    def sequence_processing(self, X: torch.Tensor, Y: torch.Tensor = None) -> List[torch.Tensor]:\n",
    "        output = []\n",
    "        for i in range(X.shape[1]):\n",
    "            self.hidden_state = self.hidden_activation(self.input_linear(X[:, i, :]) + self.hidden_linear(self.hidden_state))\n",
    "            output.append(self.output_activation(self.output_linear(self.hidden_state)).unsqueeze(1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_Saved_Output](Images/RNN_Saved_Output.jpg)\n",
    "\n",
    "_Teacher Forcing_\n",
    "\n",
    "Instead of the previous output, the previous target valued is used to compute the immidiate hidden state.\n",
    "\n",
    "![RNN_Teacher_Forcing](Images/RNN_Teacher_Forcing.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBasic_OutputRecurrence(RNNModule):\n",
    "    # Returns one output for each sequence input, i.e. returns another whole sequence\n",
    "    # Each state is computed using the immidiate input and the previous output\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation = 'tanh', output_activation = 'sigmoid'):\n",
    "        super().__init__(input_size, output_size, output_size, activation)\n",
    "        # the previous hidden state is the saved previous \n",
    "        \n",
    "    def sequence_processing(self, X: torch.Tensor, Y: torch.Tensor = None) -> List[torch.Tensor]:\n",
    "        output = []\n",
    "        for i in range(X.shape[1]):\n",
    "            hidden_state = self.hidden_activation(self.input_linear(X[:, i, :]) + self.hidden_linear(self.hidden_state))\n",
    "            output.append(self.output_activation(self.output_linear(self.hidden_state)).unsqueeze(1))\n",
    "            self.hidden_state = output[-1]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_Single_Output](Images/RNN_Single_Output.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNBasic_SingleOutput(RNNModule):\n",
    "    # Returns one output for each sequence input, i.e. returns another whole sequence\n",
    "    # Each state is computed using the immidiate input and the previous hidden state.\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation = 'tanh'):\n",
    "        super().__init__(input_size, hidden_size, output_size, activation)\n",
    "        \n",
    "    def sequence_processing(self, X: torch.Tensor, Y: torch.Tensor = None) -> List[torch.Tensor]:\n",
    "        for i in range(X.shape[1]):\n",
    "            self.hidden_state = self.hidden_activation(self.input_linear(X[:, i, :]) + self.hidden_linear(self.hidden_state))\n",
    "        \n",
    "        output = self.output_activation(self.output_linear(self.hidden_state)).unsqueeze(1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, n_days):\n",
    "#         super(RNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.n_layers = num_layers\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "#         self.output = nn.Linear(hidden_size, n_days)\n",
    "                            \n",
    "        \n",
    "#     def forward(self, x, hidden):\n",
    "#         out, hidden = self.rnn(x, hidden)\n",
    "#         out = hidden[-1]\n",
    "#         out = self.output(out)\n",
    "        \n",
    "#         return out, hidden\n",
    "    \n",
    "# def train_rnn(model, dataloader, loss_function, optimizer, epochs, scheduler = None):\n",
    "#     epoch_losses = []\n",
    "#     mean = lambda xs : sum(xs)/len(xs) \n",
    "#     for i in range(1, epochs+1):\n",
    "#         temp_losses = []\n",
    "#         for sample in dataloader: \n",
    "#                 optimizer.zero_grad()\n",
    "#                 hidden = None\n",
    "                \n",
    "#                 inputs = sample[0]\n",
    "#                 targets = sample[1]\n",
    "#                 output, hidden = model(inputs, hidden)\n",
    "                \n",
    "#                 loss = loss_function(output, targets)\n",
    "#                 temp_losses.append(loss.item())\n",
    "# #                 print(loss)\n",
    "#                 loss.backward(retain_graph = True)\n",
    "#                 optimizer.step()\n",
    "                \n",
    "#         if scheduler != None:\n",
    "#             scheduler.step()\n",
    "            \n",
    "#         epoch_losses.append(mean(temp_losses))\n",
    "#         if i%10 == 0:\n",
    "#             print('Epoch: {}/{}.............'.format(i, epochs), end=' ')\n",
    "#             print(\"Loss: {:.4f}\".format(epoch_losses[-1]))\n",
    "    \n",
    "#     return epoch_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
